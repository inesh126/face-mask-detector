{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "V3-neor_E439"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "YvhmOHf3ThRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d omkargurav/face-mask-dataset"
      ],
      "metadata": {
        "id": "F0fO41ZTT0HZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "dataset = '/content/face-mask-dataset.zip'\n",
        "with ZipFile(dataset,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted')"
      ],
      "metadata": {
        "id": "fzth7J9tUPDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "YuoMDFDVVggi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with_mask_images = os.listdir('/content/data/with_mask')\n",
        "# print(with_mask_path[0:5])\n",
        "without_mask_images = os.listdir('/content/data/without_mask')\n",
        "type(without_mask_images[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJoAzbc7XkWQ",
        "outputId": "fc6434e1-5a8d-4f82-fed5-904d4553bb1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating labels\n",
        "with_mask_labels = [1]*3725\n",
        "without_mask_labels = [0]*3828\n",
        "# print(\"with mask\", with_mask_labels[0:5])\n",
        "# print(\"without mask\", without_mask_labels)\n",
        "labels = with_mask_labels + without_mask_labels\n",
        "print(len(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGGD-uy_dOoX",
        "outputId": "747e0ab7-b5e6-4a9c-c881-61f6d95168c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Display\n",
        "img = mpimg.imread('/content/data/with_mask/with_mask_11.jpg')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pDLxaRCJevcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = mpimg.imread('/content/data/without_mask/without_mask_1155.jpg')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BVRH6QFjfKhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting images to numpy array\n",
        "with_mask_path = '/content/data/with_mask/'\n",
        "\n",
        "data = []\n",
        "\n",
        "for img_file in with_mask_images:\n",
        "\n",
        "  image = Image.open(with_mask_path + img_file)\n",
        "  image = image.resize((128,128))\n",
        "  image = image.convert('RGB')\n",
        "  image = np.array(image)\n",
        "  data.append(image)\n",
        "\n",
        "\n",
        "\n",
        "without_mask_path = '/content/data/without_mask/'\n",
        "\n",
        "\n",
        "for img_file in without_mask_images:\n",
        "  # print( type(img_file))\n",
        "  # print(type(without_mask_path))\n",
        "\n",
        "  image = Image.open(without_mask_path + img_file)\n",
        "  image = image.resize((128,128))\n",
        "  image = image.convert('RGB')\n",
        "  image = np.array(image)\n",
        "  data.append(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQxkoA0ZgaO8",
        "outputId": "96458095-ea8a-45b5-cd56-34ef8e4c2a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert image list and data list to numpy array\n",
        "X = np.array(data)\n",
        "Y = np.array(labels)\n",
        "# print(len(labels))\n",
        "# print(len(X))\n",
        "# Train test split\n",
        "X_train,X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 2)\n",
        "# Scaling data\n",
        "X_train_scaled = X_train/255\n",
        "X_test_scaled = X_test/255"
      ],
      "metadata": {
        "id": "Q8JD4Xvkiy7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(128,128,3)))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(keras.layers.Dense(num_of_classes, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=5)\n",
        "loss, accuracy = model.evaluate(X_test_scaled, Y_test)\n",
        "print('Test Accuracy =', accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "M2wrKPTZkU7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = history\n",
        "\n",
        "# plot the loss value\n",
        "plt.plot(h.history['loss'], label='train loss')\n",
        "plt.plot(h.history['val_loss'], label='validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plot the accuracy value\n",
        "plt.plot(h.history['acc'], label='train accuracy')\n",
        "plt.plot(h.history['val_acc'], label='validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W1SRyaeMTZw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_image_path = input('Path of the image to be predicted: ')\n",
        "\n",
        "input_image = cv2.imread(input_image_path)\n",
        "\n",
        "cv2_imshow(input_image)\n",
        "\n",
        "input_image_resized = cv2.resize(input_image, (128,128))\n",
        "\n",
        "input_image_scaled = input_image_resized/255\n",
        "\n",
        "input_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3])\n",
        "\n",
        "input_prediction = model.predict(input_image_reshaped)\n",
        "\n",
        "print(input_prediction)\n",
        "\n",
        "\n",
        "input_pred_label = np.argmax(input_prediction)\n",
        "\n",
        "print(input_pred_label)\n",
        "\n",
        "\n",
        "if input_pred_label == 1:\n",
        "\n",
        "  print('The person in the image is wearing a mask')\n",
        "\n",
        "else:\n",
        "\n",
        "  print('The person in the image is not wearing a mask')"
      ],
      "metadata": {
        "id": "1CT6yeuMTh8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_image_path = input('Path of the image to be predicted: ')\n",
        "\n",
        "input_image = cv2.imread(input_image_path)\n",
        "\n",
        "cv2_imshow(input_image)\n",
        "\n",
        "input_image_resized = cv2.resize(input_image, (128,128))\n",
        "\n",
        "input_image_scaled = input_image_resized/255\n",
        "\n",
        "input_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3])\n",
        "\n",
        "input_prediction = model.predict(input_image_reshaped)\n",
        "\n",
        "print(input_prediction)\n",
        "\n",
        "\n",
        "input_pred_label = np.argmax(input_prediction)\n",
        "\n",
        "print(input_pred_label)\n",
        "\n",
        "\n",
        "if input_pred_label == 1:\n",
        "\n",
        "  print('The person in the image is wearing a mask')\n",
        "\n",
        "else:\n",
        "\n",
        "  print('The person in the image is not wearing a mask')"
      ],
      "metadata": {
        "id": "qaUfhX9iTo8I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}